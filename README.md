# Classical Machine Learning Algorithms

This repository is a collection of classical machine learning algorithms implemented in Python. It includes a variety of algorithms from different areas of machine learning, such as ensemble methods, reinforcement learning, semi-supervised learning, supervised learning, and unsupervised learning.

## Table of Contents

- [Ensemble](#ensemble)
  - [Bagging](ensemble/bagging.py)
  - [Boosting](ensemble/boosting.py)
- [Reinforcement Learning](#reinforcement-learning)
  - [Deep Q-Network (DQN)](reinforcement/dqn.py)
  - [Q-Learning](reinforcement/q-learning.py)
  - [Temporal Difference (TD) Learning](reinforcement/td-learning.py)
- [Semi-Supervised Learning](#semi-supervised-learning)
  - [Label Propagation](semi-supervised/label-propagation.py)
  - [Label Spreading](semi-supervised/label-spreading.py)
- [Supervised Learning](#supervised-learning)
  - [Decision Trees](supervised/decision-trees.py)
  - [Huber Regressor](supervised/huber-regressor.py)
  - [Lasso and Ridge Regression](supervised/lasso-ridge.py)
  - [Linear SVM](supervised/linear-SVM.py)
  - [Linear Regression](supervised/linear-regression.py)
  - [Logistic Regression](supervised/logistic-regression.py)
  - [Naive Bayes](supervised/naive-bayes.py)
  - [Polynomial Regression](supervised/polynomical-regression.py)
  - [Random Forests](supervised/random-forests.py)
- [Unsupervised Learning](#unsupervised-learning)
  - [Isolation Forest](unsupervised/isolation-forest.py)
  - [K-Means Clustering](unsupervised/k-means-clustering.py)
  - [Principal Component Analysis (PCA)](unsupervised/pca.py)
  - [t-SNE](unsupervised/t-sne.py)

## Usage
Each folder in the repository contains a Python file corresponding to the algorithm mentioned. To use an algorithm, navigate to the respective folder and run the Python file.

## Contributing
Contributions to this repository are welcome. Please feel free to fork the repo, add your contributions, and then make a pull request.

## License
This project is open-sourced under the MIT license.
